{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilesInfo = [\"Trump Speechs\\speech_0.txt\",\"Trump Speechs\\speech_1.txt\",\"Trump Speechs\\speech_2.txt\", \n",
    "             \"Trump Speechs\\speech_3.txt\",\"Trump Speechs\\speech_4.txt\",\"Trump Speechs\\speech_5.txt\",\n",
    "             \"Trump Speechs\\speech_6.txt\",\"Trump Speechs\\speech_7.txt\",\"Trump Speechs\\speech_8.txt\",\n",
    "             \"Trump Speechs\\speech_9.txt\",\"Trump Speechs\\speech_10.txt\",\"Trump Speechs\\speech_11.txt\",\n",
    "             \"Trump Speechs\\speech_12.txt\",\"Trump Speechs\\speech_13.txt\",\"Trump Speechs\\speech_14.txt\",\n",
    "             \"Trump Speechs\\speech_15.txt\",\"Trump Speechs\\speech_16.txt\",\"Trump Speechs\\speech_17.txt\",\n",
    "             \"Trump Speechs\\speech_18.txt\",\"Trump Speechs\\speech_19.txt\",\"Trump Speechs\\speech_20.txt\",\n",
    "             \"Trump Speechs\\speech_21.txt\",\"Trump Speechs\\speech_22.txt\",\"Trump Speechs\\speech_23.txt\",\n",
    "             \"Trump Speechs\\speech_24.txt\",\"Trump Speechs\\speech_25.txt\",\"Trump Speechs\\speech_26.txt\",\n",
    "             \"Trump Speechs\\speech_27.txt\",\"Trump Speechs\\speech_28.txt\",\"Trump Speechs\\speech_29.txt\",\n",
    "             \"Trump Speechs\\speech_30.txt\",\"Trump Speechs\\speech_31.txt\",\"Trump Speechs\\speech_32.txt\",\n",
    "             \"Trump Speechs\\speech_33.txt\",\"Trump Speechs\\speech_34.txt\",\"Trump Speechs\\speech_35.txt\",\n",
    "             \"Trump Speechs\\speech_36.txt\",\"Trump Speechs\\speech_37.txt\",\"Trump Speechs\\speech_38.txt\",\n",
    "             \"Trump Speechs\\speech_39.txt\",\"Trump Speechs\\speech_40.txt\",\"Trump Speechs\\speech_41.txt\",\n",
    "             \"Trump Speechs\\speech_42.txt\",\"Trump Speechs\\speech_43.txt\",\"Trump Speechs\\speech_44.txt\",\n",
    "             \"Trump Speechs\\speech_45.txt\",\"Trump Speechs\\speech_46.txt\",\"Trump Speechs\\speech_47.txt\",\n",
    "             \"Trump Speechs\\speech_48.txt\",\"Trump Speechs\\speech_49.txt\",\"Trump Speechs\\speech_50.txt\",\n",
    "             \"Trump Speechs\\speech_51.txt\",\"Trump Speechs\\speech_52.txt\",\"Trump Speechs\\speech_53.txt\",\n",
    "             \"Trump Speechs\\speech_54.txt\",\"Trump Speechs\\speech_55.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function implements all the pre processing\n",
    "\n",
    "def PreProcessor(data):\n",
    "    \n",
    "    stopwords= [\"a\",\"is\",\"the\",\"of\",\"all\",\"and\",\"to\",\"can\",\"be\",\"as\",\"once\",\"for\",\"at\",\"am\",\"are\",\"has\",\n",
    "              \"have\",\"had\",\"up\",\"his\",\"her\",\"in\",\"on\",\"no\",\"we\",\"do\"]\n",
    "    DocList = [] # This list stores terms in a document\n",
    "    \n",
    "    # replacing full stops with spaces because \n",
    "    # while tokenization if there is no space between end of one sentence and start of the other sentence\n",
    "    # two different words are tokenized as one\n",
    "    \n",
    "    data = data.replace('.',' ')\n",
    "\n",
    "    #replacing all special characters with spaces to avoid the issues while tokenization\n",
    "\n",
    "    data = data.replace('[',' ')\n",
    "    data = data.replace(']',' ')\n",
    "    data = data.replace(')',' ')\n",
    "    data = data.replace('(',' ')\n",
    "    data = data.replace(':',' ')\n",
    "    data = data.replace(';',' ')\n",
    "    data = data.replace('?',' ')\n",
    "    data = data.replace('\"',' ')\n",
    "    data = data.replace(',',' ')\n",
    "    data = data.replace('!',' ')\n",
    "    data = data.replace('&',' ')\n",
    "    data = data.replace('-',' ')\n",
    "    data = data.replace('$',' ')\n",
    "    data = data.replace('/',' ')\n",
    "    data = data.replace('%',' ')\n",
    "    data = data.replace('â€”',' ')\n",
    "\n",
    "    #removing punctuation marks\n",
    "\n",
    "    data = data.replace(\"'s\",\" is\")\n",
    "    data = data.replace(\"'ve\",\" have\")\n",
    "    data = data.replace(\"'ll\",\" will\")\n",
    "    data = data.replace(\"'re\",\" are\")\n",
    "    data = data.replace(\"'d\",\" would\")\n",
    "    data = data.replace(\"'m\",\" am\")\n",
    "    data = data.replace(\"n't\",\" not\")\n",
    "\n",
    "    #removing notations from the speech \n",
    "\n",
    "    data = data.replace('(ph)',' ')\n",
    "    data = data.replace(\"'\",' ')\n",
    "    \n",
    "    #removing digits \n",
    "    \n",
    "    data = data.replace(\"1\",'')\n",
    "    data = data.replace(\"2\",'')\n",
    "    data = data.replace(\"3\",'')\n",
    "    data = data.replace(\"4\",'')\n",
    "    data = data.replace(\"5\",'')\n",
    "    data = data.replace(\"6\",'')\n",
    "    data = data.replace(\"7\",'')\n",
    "    data = data.replace(\"8\",'')\n",
    "    data = data.replace(\"9\",'')\n",
    "    data = data.replace(\"0\",'')\n",
    "    \n",
    "    # this function is used to tokenize the string\n",
    "    \n",
    "    Data = data.split() \n",
    "    \n",
    "    for token in Data :\n",
    "        \n",
    "        newtoken = token.lower()  # This function implements case folding\n",
    "        \n",
    "        #this if condition is used to check if a word is not a stopword\n",
    "\n",
    "        if newtoken not in stopwords :\n",
    "                    \n",
    "                # If a word is not a stopword , it is passed through lemmitizer \n",
    "                # it is then added to the list of tokens (vocabulary of a document)\n",
    "       \n",
    "                lemmatizedtoken = Lemmatizer.lemmatize(newtoken)  # This function implements lemmitization\n",
    "                DocList.append(newtoken)                          # List of tokens for each document (vocabulary of a document)\n",
    "                \n",
    "    return DocList                                                # returns the list of terms for a document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to create the dictionary\n",
    "\n",
    "def CreateDictionary() :\n",
    "\n",
    "    Dictionary = {}                       # This dictionary is used to store all the terms for each document\n",
    "    i=0\n",
    "\n",
    "    for File in FilesInfo:                 # this loop iterates through the files \n",
    "        file=open(File , 'r')              # opens a file for reading \n",
    "        next(file)                         # skips the first line of the file\n",
    "        data = file.read()                 # reading the file into a string\n",
    "        Dictionary[i] = PreProcessor(data) # storing the list of each document into a dictionary\n",
    "        i += 1                             # this is used for maintaing index of the dictionary\n",
    "\n",
    "    return(Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to calculate document frequency of the vocabulary\n",
    "\n",
    "def df_Calculator(Dictionary):\n",
    "    \n",
    "    # DocFreq is a dictionary with \"tokens\" as \"keys\" and \"document freq\" as \"key values\"\n",
    "\n",
    "    DocFreq = {} \n",
    "\n",
    "    for i in Dictionary:                                       # i is the index of Dictionary i-e doc id\n",
    "        for word in Dictionary[i]:                             # for word in document\n",
    "            if word not in DocFreq.keys():                     # each word is added once in DocFreq \n",
    "                count = 0                                      # counter for the document freq\n",
    "                for j in Dictionary:                           # inner loop \n",
    "                    if word in Dictionary[j]:                  # if the word is in the particular document\n",
    "                        count += 1                             # increments the document frequency\n",
    "                DocFreq[word]=count                            # storing document freq against each word \n",
    "\n",
    "    DocFreq=  collections.OrderedDict(sorted(DocFreq.items())) # to sort in alphabetical order\n",
    "\n",
    "    return(DocFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to calculate term frequency of the vocabulary\n",
    "\n",
    "def tf_Calculator(Dictionary):\n",
    "    \n",
    "    # TermFreq is a dictionary with \"tokens\" as \"keys\" against which doc ids and term freq is stored\n",
    "\n",
    "    TermFreq = {}\n",
    "\n",
    "    for i in Dictionary:                        # i is the index of Dictionary i-e doc id\n",
    "        for word in Dictionary[i]:              # for word in document\n",
    "            if word not in TermFreq.keys():     # each word is added once in DocFreq\n",
    "                TermFreq[word]={}               # a dictionary is made for each word \n",
    "                for j in Dictionary:\n",
    "                    TermFreq[word][j]=[]        # a list against each word and doc id\n",
    "                    count = 0                   # counter for the term freq\n",
    "                    for term in Dictionary[j]:  \n",
    "                        if word == term :       # if the words appear in that document\n",
    "                            count += 1          # increments the term frequency\n",
    "                    TermFreq[word][j]=count     # appending the term freq against doc id of each word\n",
    "                \n",
    "    TermFreq=  collections.OrderedDict(sorted(TermFreq.items())) \n",
    "\n",
    "    return(TermFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to calculate idf values \n",
    "\n",
    "def idf_Calculator(DocFreq):\n",
    "\n",
    "    N = 56                                                # Total number of documents \n",
    "\n",
    "    idfValues = {}                                        # Dictionary to store Idf values \n",
    "\n",
    "    for i in DocFreq:                                     # i is a word in DocFreq\n",
    "        idfValues[i] = (math.log10(N)/float(DocFreq[i]))  # calcualates the idf value and stores in the dictionary\n",
    "        \n",
    "    return(idfValues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to calculate td-idf values \n",
    "\n",
    "def tfidf_Calculator(TermFreq,idfValues):\n",
    "    \n",
    "\n",
    "    tf_idf = {}                                             # Dictionary to store tf-idf values \n",
    "\n",
    "    for i in TermFreq :                                     # i is a word in TermFreq\n",
    "        tf_idf[i] = []                                      #creates a list against each word \n",
    "        for j in TermFreq[i].keys() :                       # j is the doc id \n",
    "            tf_idf[i].append(TermFreq[i][j] * idfValues[i]) #stores the tf-idf values in the list \n",
    "                                                            # the index of the list is the doc id\n",
    "        \n",
    "    return(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to create document vectors \n",
    "\n",
    "def CreateDocVector(tf_idf):\n",
    "\n",
    "    DocumentVectors = {}                                  # Dictionary to store document vectors\n",
    "                                                          # document vector is stored against the index in dictionary \n",
    "                                                          # where index represents doc id\n",
    "        \n",
    "    for i in range(0,56):                                 # for the total no of documents\n",
    "        DocumentVectors[i] = []\n",
    "        for word in tf_idf:                               # terms in the tf_idf dictionary\n",
    "            DocumentVectors[i].append(tf_idf[word][i])    # appends the tf-idf term by term in the list of a document\n",
    "        \n",
    "    for i in DocumentVectors:\n",
    "        DocumentVectors[i] = np.array(DocumentVectors[i]) # converts into a vector\n",
    "        \n",
    "    return(DocumentVectors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to create the query vector \n",
    "\n",
    "def CreateQueryVector(query,DocFreq):\n",
    "\n",
    "    query = PreProcessor(query) # the query is preprocessed\n",
    "    \n",
    "    QueryVector = []           \n",
    "\n",
    "    for term in DocFreq :               # for all the terms in the vocabulary\n",
    "        count = 0                       # counter for term freq of query\n",
    "        for token in query:             # terms in query\n",
    "            if term == token:           # if the term is in the query\n",
    "                count += 1              # increments the freq\n",
    "        QueryVector.append(count) \n",
    " \n",
    "    QueryVector = np.array(QueryVector) # converts into a vector\n",
    "    return(QueryVector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to calculate the cosine similarity \n",
    "\n",
    "def cosinevalue(a,b):\n",
    "    \n",
    "    dotproduct = np.dot(a, b)                       #calculates dot product of two vectors\n",
    "    magnitude_a = np.linalg.norm(a)                 #calculates magnitude of first vector\n",
    "    magnitude_b = np.linalg.norm(b)                 #calculates magnitude of second vector\n",
    "    return (dotproduct/(magnitude_a * magnitude_b)) #returns the value of cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function is used to calculate the cosine similarities\n",
    "\n",
    "def CosineSimilarity_Calculator(DocumentVectors,QueryVector):\n",
    "    \n",
    "    CosineValues = {}    # Dictionary to store the cosine values of each document                                         \n",
    "\n",
    "    for i in DocumentVectors:\n",
    "        CosineValues[i]=cosinevalue(DocumentVectors[i],QueryVector) # cosine value is stored against doc id\n",
    "\n",
    "    return(CosineValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to retrieve the resultant documents\n",
    "\n",
    "def Result_Calculator(CosineValues): \n",
    "\n",
    "    NoOfDocRetreived = 0             \n",
    "    RetrievedResult = []                  #stores only the document ids\n",
    "    RetrievedDocuments = []               #stores document ids with their cosine values\n",
    "\n",
    "    for i in CosineValues:\n",
    "        if(CosineValues[i]>=0.0005):      #if the value is greater than or equal to alpha\n",
    "            RetrievedDocuments.append((CosineValues[i],i))\n",
    "            NoOfDocRetreived += 1         #increments the no of documents retrieved\n",
    "\n",
    "    RetrievedDocuments.sort(reverse=True) #sorts in the order of decreasing cosine value\n",
    "\n",
    "    for cosinevalue , docid in RetrievedDocuments:\n",
    "        RetrievedResult.append(docid)\n",
    "    \n",
    "    entry2.insert(END,RetrievedResult)    # prints the result to the GUI\n",
    "    entry3.insert(END,NoOfDocRetreived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                        # Built in library for vectors\n",
    "import nltk\n",
    "import collections\n",
    "import math                               # Built in library to implement the built in logarithmic function\n",
    "from nltk.stem import WordNetLemmatizer   # Built in library for lemmitization\n",
    "Lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def SimpleVectorQuery():                  # Function for Simple Vector Query\n",
    "    \n",
    "    query = entry1.get()                  # retrieves the input \n",
    "    RetrieveResult(query)\n",
    "    \n",
    "def ComplexVectorQuery():                 # Function for Simple Vector Query\n",
    "    \n",
    "    query = entry1.get()                  # retrieves the input \n",
    "    RetrieveResult(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main implementation of the Vector Space Model\n",
    "\n",
    "Dictionary = CreateDictionary()                                             # a vocabulary of unique terms is created\n",
    "DocFreq = df_Calculator(Dictionary)                                         # df is calculated\n",
    "TermFreq = tf_Calculator(Dictionary)                                        # tf is calculated\n",
    "idfValues = idf_Calculator(DocFreq)                                         # idf is calculated\n",
    "tf_idf = tfidf_Calculator(TermFreq,idfValues)                               # tf_idf is calculated \n",
    "DocumentVectors = CreateDocVector(tf_idf)                                   # Document Vectors are created\n",
    "\n",
    "def RetrieveResult(query):\n",
    "    \n",
    "    QueryVector = CreateQueryVector(query,DocFreq)                          # Query Vector is created\n",
    "    CosineValues = CosineSimilarity_Calculator(DocumentVectors,QueryVector) # cosine similarity is calculated\n",
    "    Result_Calculator(CosineValues)                                         # result is fetched based on alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to refresh the GUI for the next query search\n",
    "\n",
    "def RefreshGUI():\n",
    "    \n",
    "    entry1.delete(0,'end')\n",
    "    entry2.delete(1.0,END)\n",
    "    entry3.delete(1.0,END)\n",
    "\n",
    "# This function is used to close the GUI window\n",
    "\n",
    "def CloseGUI():\n",
    "    \n",
    "    win.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet implements the GUI \n",
    "\n",
    "from tkinter import *                               # Built in library \n",
    "\n",
    "win = Tk()                                          # creates the GUI window\n",
    "win.configure(background='SteelBlue4')              # sets the window colour\n",
    "win.title(\"Information Retrieval Assignment # 02 \") # used to set the title of the window\n",
    "win.geometry(\"1050x400\")                            # used to set the size of the window \n",
    "\n",
    "greeting = Label(win,text=\"QUERY PROCESSING INTERFACE\",bg='SteelBlue4',fg=\"black\",height=2,font=(\"Arial\",16,\"bold\")) \n",
    "greeting.place(x=405,y=10)                         # used to set the position\n",
    "\n",
    "label1 = Label(win,text=\"Type Your Query \",bg='SteelBlue4',fg='black', font=('helvetica', 12, 'bold')) # used to create the input statement\n",
    "entry1 = Entry(win)                                # used to create the input box \n",
    "\n",
    "label1.place(x=510,y=90)                           # used to set the position of the input statement\n",
    "entry1.place(x=420,y=120,width=310,height=23)      # used to set the position of the input box\n",
    "\n",
    "v = IntVar()\n",
    "\n",
    "button1 = Radiobutton(win,text='Simple Vector Query' , variable=v , value = 1 ,bg='SteelBlue4', fg='black', font=('helvetica', 9, 'bold') )\n",
    "button1.place(x=420,y=150)                         # used to set the position of the button \n",
    "\n",
    "button2 = Radiobutton(win,text='Complex Vector Query', variable=v ,value = 2 ,bg='SteelBlue4', fg='black', font=('helvetica', 9, 'bold') )\n",
    "button2.place(x=570,y=150)                         # used to set the position of the button \n",
    "\n",
    "\n",
    "if(v.get()==1):                                    # if the query is simple vector query \n",
    "    button = Button(win,text='Find Result', command=SimpleVectorQuery, bg='light grey', fg='black', font=('helvetica', 9, 'bold')) \n",
    "    button.place(x=520,y=190,width=100)            # used to set the position of the button \n",
    "\n",
    "else:                                              # if the query is complex vector query\n",
    "    button = Button(win,text='Find Result', command=ComplexVectorQuery, bg='light grey', fg='black', font=('helvetica', 9, 'bold')) \n",
    "    button.place(x=520,y=190,width=100)            # used to set the position of the button \n",
    "    \n",
    "\n",
    "label2 = Label(win,text=\"Retrieved Documents : \",bg='SteelBlue4' , font=('helvetica', 9, 'bold'))\n",
    "label2.place(x=10,y=260)\n",
    " \n",
    "entry2 = Text(win, height=2)                       # creates the text widget that stores retrieved documents\n",
    "entry2.place(x=150,y=260,width=890)                # used to set the position of the widget\n",
    "entry2.config(state=NORMAL)\n",
    "\n",
    "label3 = Label(win,text=\"Length : \",bg='SteelBlue4', font=('helvetica', 9, 'bold'))\n",
    "label3.place(x=70,y=310)\n",
    "\n",
    "entry3 = Text(win, height=2)                       # creates the text widget that stores length of retrieved result \n",
    "entry3.place(x=150,y=310, width=80)                # used to set the position of the widget\n",
    "entry2.config(state=NORMAL)\n",
    "\n",
    "button1 = Button(win,text='Clear',width=10, command=RefreshGUI ,bg='light grey', fg='black', font=('helvetica', 9, 'bold'))\n",
    "button1.place(x=480,y=350)                        # places the REFRESH button\n",
    "\n",
    "button2 = Button(win,text='Exit',width=10, command=CloseGUI , bg='light grey', fg='black', font=('helvetica', 9, 'bold'))\n",
    "button2.place(x=580,y=350)                        # places the EXIT button\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
